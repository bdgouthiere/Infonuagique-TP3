{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdgouthiere/Infonuagique-TP3/blob/main/TP2_V_0_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P5Qtj2QePgo"
      },
      "source": [
        "# Installation des packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p64CM7lHYFMk"
      },
      "outputs": [],
      "source": [
        "!pip install rembg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1WbZM2gcba1"
      },
      "source": [
        "Import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ8Z4G92cQgq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from cv2 import imread, imwrite, resize, cvtColor, INTER_AREA, COLOR_BGR2RGBA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow import float32\n",
        "from keras.applications.efficientnet import preprocess_input\n",
        "from keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from keras import layers, Sequential, Model\n",
        "from keras.layers import Dense, Activation, BatchNormalization, Input, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from rembg import remove\n",
        "from PIL import Image\n",
        "\n",
        "from pickle import dump, HIGHEST_PROTOCOL\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXy-wOIacQ0k"
      },
      "source": [
        "Class Animal Classification\n",
        "\n",
        "\n",
        "# Main Code\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JLAFyUXn5By1",
        "outputId": "449f12c3-77aa-46cb-b80b-f0961430f673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/zebra\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/wombat\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/woodpecker\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/turtle\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/squirrel\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/starfish\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/whale\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/turkey\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/tiger\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/swan\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/wolf\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/squid\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/sparrow\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/snake\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/sheep\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/shark\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/seal\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/seahorse\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/rhinoceros\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/rat\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/reindeer\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/raccoon\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/sandpiper\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/porcupine\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/possum\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/pig\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/pelecaniformes\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/ox\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/pigeon\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/panda\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/penguin\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/oyster\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/parrot\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/otter\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/owl\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/lizard\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/mouse\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/orangutan\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/moth\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/mosquito\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/octopus\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/okapi\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/lobster\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/leopard\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/lion\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/ladybugs\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/horse\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hummingbird\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/koala\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/kangaroo\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/jellyfish\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hyena\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hornbill\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hedgehog\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hippopotamus\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hare\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/fox\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/goose\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/goldfish\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/goat\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/hamster\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/grasshopper\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/gorilla\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/fly\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/flamingo\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/elephant\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/deer\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/dolphin\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/dragonfly\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/duck\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/donkey\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/dog\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/eagle\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/crab\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/crow\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/caterpillar\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/cat\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/chimpanzee\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/boar\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/cockroach\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/butterfly\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/cow\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/coyote\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/bison\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/beetle\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/bee\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/bear\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/badger\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/antelope\n",
            "Chargement du dossier: /content/drive/MyDrive/Data/TP2/Dataset/animals-4/bat\n",
            "                                             imgpath   labels\n",
            "0  /content/drive/MyDrive/Data/TP2/Data/oyster/fa...   oyster\n",
            "1  /content/drive/MyDrive/Data/TP2/Data/dolphin/0...  dolphin\n",
            "2  /content/drive/MyDrive/Data/TP2/Data/squid/417...    squid\n",
            "3  /content/drive/MyDrive/Data/TP2/Data/squid/16c...    squid\n",
            "4  /content/drive/MyDrive/Data/TP2/Data/oyster/07...   oyster\n",
            "(4297, 2)\n",
            "                                             imgpath   labels\n",
            "0  /content/drive/MyDrive/Data/TP2/Data/lion/67e2...     lion\n",
            "1  /content/drive/MyDrive/Data/TP2/Data/deer/66c5...     deer\n",
            "2  /content/drive/MyDrive/Data/TP2/Data/octopus/0...  octopus\n",
            "3  /content/drive/MyDrive/Data/TP2/Data/possum/5b...   possum\n",
            "4  /content/drive/MyDrive/Data/TP2/Data/bee/927d3...      bee\n",
            "(1075, 2)\n",
            "Found 4297 validated image filenames belonging to 90 classes.\n",
            "Found 1075 validated image filenames belonging to 90 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "input_1 True\n",
            "conv1_pad True\n",
            "conv1_conv True\n",
            "conv1_bn False\n",
            "conv1_relu True\n",
            "pool1_pad True\n",
            "pool1_pool True\n",
            "conv2_block1_1_conv True\n",
            "conv2_block1_1_bn False\n",
            "conv2_block1_1_relu True\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputLayer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     multiple                  0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 256)               1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 90)                23130     \n",
            "                                                                 \n",
            " activationLayer (Activatio  (None, 90)                0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24136410 (92.07 MB)\n",
            "Trainable params: 24029658 (91.67 MB)\n",
            "Non-trainable params: 106752 (417.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d56cb0a1c4e9>\u001b[0m in \u001b[0;36m<cell line: 258>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimalsClassificationEntrainement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentrainement_modele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffichage_resultat_entrainement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d56cb0a1c4e9>\u001b[0m in \u001b[0;36mentrainement_modele\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mentrainement_modele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     self.history = self.modele.fit(\n\u001b[0m\u001b[1;32m    209\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         ):\n\u001b[1;32m   1744\u001b[0m             \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m             data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1746\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorExactEvalDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1293\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;31m# Since we have to know the dtype of the python generator when we build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;31m# the dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     def _handle_multiprocessing(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         ]\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    371\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from genericpath import exists\n",
        "class AnimalsClassificationEntrainement(object):\n",
        "  def __init__(self, **kwargs):\n",
        "    self.IMAGE_TAILLE: tuple = (224, 224)\n",
        "    self.BATCH_TAILLE: int = 16\n",
        "    self.OUTPUT_SIZE: tuple = (224, 224)\n",
        "    self.REMOVE_BACKGROUND: bool = kwargs.get(\"remove_background\", False)\n",
        "    self.dossier_modeles: str = kwargs.get(\"dossier_modeles\", \"/content/drive/MyDrive/Data/TP2/Models-3-WithBG\")\n",
        "    self.dossier_donnees: str = kwargs.get(\"dossier_donnees\", \"/content/drive/MyDrive/Data/TP2/Data\")\n",
        "    self.dossier_dataset: str = kwargs.get(\"dossier_dataset\", \"/content/drive/MyDrive/Data/TP2/Dataset/animals-4\")\n",
        "    self.fichier_labels: str = kwargs.get(\"fichier_labels\", \"/content/drive/MyDrive/Data/TP2/Models-3-WithBG/label_dict.pickle\")\n",
        "    self._init_dossiers()\n",
        "    self.df: pd.DataFrame = None\n",
        "    self.df_train = None\n",
        "    self.df_validation = None\n",
        "    self.callbacks: list = []\n",
        "    self.fichier_meilleure_precision: str = os.path.join(self.dossier_modeles, \"best-model-accuracy.h5\")\n",
        "    self.fichier_meilleure_validation: str = os.path.join(self.dossier_modeles, \"best-model-val-accuracy.h5\")\n",
        "    self.modele = None\n",
        "    self.history = None\n",
        "    self.nbr_epochs = 50\n",
        "\n",
        "\n",
        "  def preparation(self) -> None:\n",
        "    self._init_dossiers()\n",
        "    self.df = self._chargement_images()\n",
        "    self._repartition_donnees()\n",
        "    self._donnees_generation_configuration()\n",
        "    self._enregistrement_labels()\n",
        "    self._configuration_modele()\n",
        "    self._callbacks()\n",
        "\n",
        "  def _init_dossiers(self) -> None:\n",
        "    self._dossier_creation(self.dossier_modeles)\n",
        "    self._dossier_creation(self.dossier_donnees)\n",
        "    self._dossier_creation(self.dossier_dataset)\n",
        "\n",
        "  def _dossier_creation(self, chemin: str) -> None:\n",
        "    if not os.path.exists(chemin):\n",
        "      os.mkdir(chemin)\n",
        "\n",
        "  def _traitement_image(self, chemin_image: str, dossier: str):\n",
        "    # Création du dossier de la catégorie s'il n'existe pas\n",
        "    dossier_images = os.path.join(self.dossier_donnees, dossier)\n",
        "    self._dossier_creation(dossier_images)\n",
        "\n",
        "    # Vérifie l'existence du fichier image\n",
        "    if not (os.path.isfile(chemin_image)):\n",
        "      return None\n",
        "\n",
        "    # Chemin de l'image nouvelle image\n",
        "    nom_fichier: str = os.path.basename(chemin_image)\n",
        "    chemin_image_redimensionnee: str = os.path.join(dossier_images, nom_fichier)\n",
        "\n",
        "    # Si l'image n'a pas été redimensionnée\n",
        "    if not (os.path.isfile(chemin_image_redimensionnee)):\n",
        "      image = imread(chemin_image)\n",
        "      hauteur, largeur = image.shape[:2]\n",
        "      ratio = 224 / max(hauteur, largeur)\n",
        "      nouvelles_dimensions = (int(largeur * ratio), int(hauteur * ratio))\n",
        "      image_redimensionnee = resize(image, nouvelles_dimensions)\n",
        "      nouvelle_image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "      x = (224 - nouvelles_dimensions[0]) // 2\n",
        "      y = (224 - nouvelles_dimensions[1]) // 2\n",
        "      nouvelle_image[y:y+nouvelles_dimensions[1], x:x+nouvelles_dimensions[0]] = image_redimensionnee\n",
        "      imwrite(chemin_image_redimensionnee, nouvelle_image)\n",
        "\n",
        "    if self.REMOVE_BACKGROUND:\n",
        "      chemin_image_redimensionnee_png = os.path.join(dossier_images, os.path.splitext(nom_fichier)[0] + \".png\")\n",
        "\n",
        "      # Si le fond de l'image n'a pas été enlevé - (présence du fichier chemin_image_redimensionnee_png)\n",
        "      if not (os.path.isfile(chemin_image_redimensionnee_png)):\n",
        "        input = Image.open(chemin_image_redimensionnee)\n",
        "        output = remove(input, alpha_matting=True, alpha_matting_foreground_threshold=120)\n",
        "        output = output.convert('RGB')\n",
        "        output.save(chemin_image_redimensionnee_png)\n",
        "        input.close()\n",
        "      return chemin_image_redimensionnee_png # Image sans background (background uni.)\n",
        "\n",
        "    return chemin_image_redimensionnee # Image avec background\n",
        "\n",
        "\n",
        "  def _chargement_images(self):\n",
        "    # Chargement des photos du dossier du dataset dans data\n",
        "    data: dict = {'imgpath': [], 'labels': []}\n",
        "    for folder in os.listdir(self.dossier_dataset):\n",
        "      folder_path: str = os.path.join(self.dossier_dataset, folder)\n",
        "      print(f\"Chargement du dossier: {folder_path}\")\n",
        "      list_image_name: list = os.listdir(folder_path)\n",
        "      for image_name in list_image_name:\n",
        "        image_path: str = os.path.join(folder_path, image_name)\n",
        "        resized_image_path = self._traitement_image(image_path, folder)\n",
        "        if resized_image_path:\n",
        "          data['imgpath'].append(resized_image_path)\n",
        "          data['labels'].append(folder)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "  def _repartition_donnees(self):\n",
        "    self.df_train, self.df_validation = train_test_split(self.df, train_size = 0.8, random_state=128)\n",
        "    self.df_train = self.df_train.reset_index(drop=True)\n",
        "    self.df_validation = self.df_validation.reset_index(drop=True)\n",
        "    print(self.df_train[['imgpath', 'labels']].head())\n",
        "    print(self.df_train.shape)\n",
        "    print(self.df_validation[['imgpath', 'labels']].head())\n",
        "    print(self.df_validation.shape)\n",
        "\n",
        "\n",
        "  def _donnees_generation_configuration(self) -> None:\n",
        "    generator = ImageDataGenerator(\n",
        "      preprocessing_function = preprocess_input,\n",
        "      horizontal_flip=True,\n",
        "      zoom_range=0.2,\n",
        "      rotation_range=20,\n",
        "      shear_range=0.2,\n",
        "      validation_split=0.2\n",
        "    )\n",
        "\n",
        "    self.train_images = generator.flow_from_dataframe(\n",
        "      dataframe=self.df_train,\n",
        "      x_col='imgpath',\n",
        "      y_col='labels',\n",
        "      target_size=self.IMAGE_TAILLE,\n",
        "      color_mode='rgb',\n",
        "      class_mode='categorical',\n",
        "      batch_size=self.BATCH_TAILLE,\n",
        "      shuffle=True,\n",
        "      seed=42\n",
        "    )\n",
        "\n",
        "    self.validation_images = generator.flow_from_dataframe(\n",
        "      dataframe = self.df_validation,\n",
        "      x_col='imgpath',\n",
        "      y_col='labels',\n",
        "      target_size=self.IMAGE_TAILLE,\n",
        "      color_mode='rgb',\n",
        "      class_mode='categorical',\n",
        "      batch_size=self.BATCH_TAILLE,\n",
        "      shuffle=True,\n",
        "    )\n",
        "\n",
        "  def _enregistrement_labels(self) ->None:\n",
        "    ## Sauvegarde les labels / numero\n",
        "    with open(self.fichier_labels, 'wb') as fichier:\n",
        "      dump(self.train_images.class_indices, fichier, protocol=HIGHEST_PROTOCOL)\n",
        "\n",
        "  def _configuration_modele(self) -> None:\n",
        "    pretrained_resnet = ResNet50(\n",
        "      input_shape=(224, 224, 3),\n",
        "      include_top=False, # we don`t need a pre-trained top layer (output layer)\n",
        "      weights='imagenet',\n",
        "      pooling='max'\n",
        "    )\n",
        "\n",
        "    # Freezing the layers of a pretrained neural network\n",
        "    for i, layer in enumerate(pretrained_resnet.layers):\n",
        "      pretrained_resnet.layers[i].trainable = False\n",
        "\n",
        "    num_classes = len(set(self.train_images.classes))\n",
        "\n",
        "    sequence = Sequential()\n",
        "    inputs = Input(shape=(224, 224, 3), name='inputLayer')\n",
        "    x = sequence(inputs)\n",
        "    pretrain_out = pretrained_resnet(x, training = False)\n",
        "    x = Dense(256)(pretrain_out)\n",
        "    x = Activation(activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "\n",
        "    outputs = Activation(activation=\"softmax\", dtype=float32, name='activationLayer')(x)\n",
        "\n",
        "    self.modele = Model(inputs=inputs, outputs=outputs)\n",
        "    pretrained_resnet.trainable = True\n",
        "    for layer in pretrained_resnet.layers:\n",
        "      if isinstance(layer, BatchNormalization): # set BatchNorm layers as not trainable\n",
        "        layer.trainable = False\n",
        "\n",
        "    # let`s see first 10 layers\n",
        "    for l in pretrained_resnet.layers[:10]:\n",
        "      print(l.name, l.trainable)\n",
        "\n",
        "    self.modele.compile(\n",
        "      optimizer = Adam(0.00001), # fine tuning requires very little learning rate\n",
        "      loss = 'categorical_crossentropy',\n",
        "      metrics = ['accuracy']\n",
        "    )\n",
        "    print(self.modele.summary())\n",
        "\n",
        "  def _callbacks(self) -> None:\n",
        "    ## Callbacks\n",
        "    self.callbacks = []\n",
        "    # Best Model Accuracy\n",
        "    bestmodel_callback = ModelCheckpoint(filepath=self.fichier_meilleure_precision, verbose=1, monitor='accuracy', save_best_only=True)\n",
        "    self.callbacks.append(bestmodel_callback)\n",
        "    # Best Model Val Accuracy\n",
        "    valmodel_callback = ModelCheckpoint(filepath=self.fichier_meilleure_validation, verbose=1, monitor='val_accuracy', save_best_only=True)\n",
        "    self.callbacks.append(valmodel_callback)\n",
        "    # EarlyStopping\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
        "    self.callbacks.append(early_stop)\n",
        "    # Reduce plateau\n",
        "    reduce_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min')\n",
        "    self.callbacks.append(reduce_plateau)\n",
        "\n",
        "\n",
        "  def entrainement_modele(self):\n",
        "    self.history = self.modele.fit(\n",
        "      self.train_images,\n",
        "      steps_per_epoch = len(self.train_images),\n",
        "      validation_data = self.validation_images,\n",
        "      validation_steps = len(self.validation_images),\n",
        "      epochs=self.nbr_epochs,\n",
        "      callbacks=self.callbacks\n",
        "    )\n",
        "    self.modele.save_weights('./checkpoints/my_checkpoint2')\n",
        "\n",
        "  def affichage_resultat_entrainement(self):\n",
        "    tr_acc = self.history.history['accuracy']\n",
        "    tr_loss = self.history.history['loss']\n",
        "    val_acc = self.history.history['val_accuracy']\n",
        "    val_loss = self.history.history['val_loss']\n",
        "    index_loss = np.argmin(val_loss)\n",
        "    val_lowest = val_loss[index_loss]\n",
        "    index_acc = np.argmax(val_acc)\n",
        "    acc_highest = val_acc[index_acc]\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize= (20, 8))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout\n",
        "    plt.show()\n",
        "\n",
        "act = AnimalsClassificationEntrainement()\n",
        "act.preparation()\n",
        "act.entrainement_modele()\n",
        "act.affichage_resultat_entrainement()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZns9TnP0f0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "END\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}